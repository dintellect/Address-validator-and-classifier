{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from flask import Flask\n",
    "from flask import request, jsonify\n",
    "#from google_images_download import google_images_download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "USER_AGENT = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "#Google Maps API KEY REQUIRED\n",
    "api_key = \"\"\n",
    "loaded_model = pickle.load(open('model.pkl', 'rb'))\n",
    "model_threshold = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Maps API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google API Map Image\n",
    "def get_map_image(address):\n",
    "    url = \"https://maps.googleapis.com/maps/api/staticmap?\"\n",
    "    center = address\n",
    "    zoom = 17\n",
    "    format = \"png\"\n",
    "    size = \"200x200\"\n",
    "    map_type = \"hybrid\"\n",
    "    link = url + \"center=\" + center + \"&zoom=\" + str(\n",
    "        zoom) + \"&size=\" + size + \"&key=\" + api_key + \"&sensor= false&format=\" + format + \"&maptype=\" + map_type\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google API Street View\n",
    "def get_street_view(address):\n",
    "    url = \"https://maps.googleapis.com/maps/api/streetview?\"\n",
    "    location = address\n",
    "    size = \"200x200\"\n",
    "    fov = 120\n",
    "    link = url + \"location=\" + location + \"&size=\" + size + \"&key=\" + api_key + \"&fov=\" + str(fov)\n",
    "    return link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google API Formats the Address\n",
    "def get_formatted_address(input):\n",
    "    url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "    r = requests.get(url + \"?address=\" + input + \"&key=\" + api_key)\n",
    "    response = json.loads(r.content.decode())\n",
    "    address = response['results'][0]['formatted_address']\n",
    "    return address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get image urls in string form  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return type list\n",
    "def get_images(address):\n",
    "    orig_stdout = sys.stdout\n",
    "    #Open file URLS.txt \n",
    "    f = open('URLS.txt', 'w')\n",
    "    sys.stdout = f\n",
    "    response = google_images_download.googleimagesdownload()\n",
    "    arguments = {\"keywords\": address, \"limit\": 1, \"print_urls\": True}\n",
    "    paths = response.download(arguments)\n",
    "    sys.stdout = orig_stdout\n",
    "    f.close()\n",
    "\n",
    "    with open('URLS.txt') as f:\n",
    "        content = f.readlines()\n",
    "    f.close()\n",
    "    urls = []\n",
    "    for j in range(len(content)):\n",
    "        if content[j][:9] == 'Completed':\n",
    "            urls.append(content[j - 1][11:-1])\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraper to fetch results from google search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_results(search_term, number_results, language_code):\n",
    "    assert isinstance(search_term, str), 'Search term must be a string'\n",
    "    assert isinstance(number_results, int), 'Number of results must be an integer'\n",
    "    escaped_search_term = search_term.replace(' ', '+')\n",
    "    #Search Engine URL\n",
    "    google_url = 'http://www.google.co.in/search?q={}&num={}&hl={}'.format(escaped_search_term, number_results,language_code)\n",
    "    response = requests.get(google_url, headers=USER_AGENT)\n",
    "    response.raise_for_status()\n",
    "    return search_term, response.text\n",
    "\n",
    "#Specify the content that need to scrapped\n",
    "def parse_results(html, keyword):\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    found_results = []\n",
    "    rank = 1\n",
    "    result_block = soup.find_all('div', attrs={'class': 'g'})\n",
    "    for result in result_block:\n",
    "        link = result.find('a', href=True)\n",
    "        title = result.find('h3')\n",
    "        description = result.find('span', attrs={'class': 'st'})\n",
    "        if link and title:\n",
    "            link = link['href']\n",
    "            title = title.get_text()\n",
    "            if description:\n",
    "                description = description.get_text()\n",
    "            if link != '#':\n",
    "                found_results.append({'description': description})\n",
    "                rank += 1\n",
    "    return (found_results)\n",
    "\n",
    "\n",
    "def get_result(address):\n",
    "    keyword, html = fetch_results(address, 15, 'en')  #Number of results from Google can be modified\n",
    "    string = parse_results(html, keyword)\n",
    "    split_add = address.replace(\",\", \" \").split(\" \")  #Tokenization\n",
    "    split_add = [x.lower() for x in split_add]        #Converting all words in lower case\n",
    "    se = []\n",
    "    for i in range(len(string)):\n",
    "        se.append(string[i]['description'])\n",
    "    str1 = ''.join(se)\n",
    "    #Tokenization\n",
    "    tok = str1.split(\" \")            \n",
    "    #Converting all words in lower case\n",
    "    tok = [x.lower() for x in tok]                    \n",
    "    # Removing special characters from string\n",
    "    files_cleaned = [re.sub(r\"[-()\\\"#/&@;:<>{}`+=~|.!?,]\", \"\", file) for file in tok] \n",
    "    #Removing all numerics\n",
    "    files_cleaned1 = [''.join(x for x in i if x.isalpha()) for i in files_cleaned] \n",
    "    add_list = [x for x in files_cleaned1 if x not in split_add]\n",
    "    stop_words = [\n",
    "        'nova', 'scotia', 'address', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\",\n",
    "        \"you've\", \"you'll\", \"you'd\", 'your',\n",
    "        'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself',\n",
    "        'it', \"it's\", 'its', 'itself',\n",
    "        'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\",\n",
    "        'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has',\n",
    "        'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as',\n",
    "        'until', 'while',\n",
    "        'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\n",
    "        'above', 'below',\n",
    "        'to', 'from', 'halifax', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then',\n",
    "        'once', 'here', 'there', 'when', 'where',\n",
    "        'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not',\n",
    "        'only', 'own', 'same', 'so', 'address', 'well', 'costs',\n",
    "        'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll',\n",
    "        'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\",\n",
    "        'hadn', \"hadn't\",\n",
    "        'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn',\n",
    "        \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'street',\n",
    "        'wasn', \"wasn't\", 'weren', \"weren't\", 'hours', 'opening', 'closing''won', 'canada', \"won't\", 'wouldn',\n",
    "        \"wouldn't\", 'find', 'north', 'south', 'reviews', 'view', 'information', 'road', 'directions', 'phone', 'number',\n",
    "        'location', 'email'\n",
    "    ]\n",
    "    a1 = [word for word in add_list if word not in stop_words]\n",
    "    files_cleaned2 = [w for w in a1 if len(w) > 3]\n",
    "    str_list = list(filter(None, files_cleaned2))\n",
    "    counts = dict(Counter(str_list))\n",
    "    your_dic = {k: v for k, v in counts.items() if v != (1)}\n",
    "    newA = sorted(your_dic, key=your_dic.get, reverse=True)[:5]\n",
    "    lib = {\n",
    "        'Residential': ['condo', 'apartment', 'property', 'bedroom', 'room', 'apt', 'bungalow', 'cabin', 'apartments',\n",
    "                        'house', 'home', 'condominium', 'farmhouse', 'apartment', 'dwelling', 'flat', 'townhouse',\n",
    "                        'home', 'community', 'homestead', 'housing', 'residency'],\n",
    "        'Non Residential': ['elementary', 'middle', 'school', 'high school', 'college', 'university', 'preschool',\n",
    "                            'daycare', 'training center', 'education', 'grocery', 'store', 'shop',\n",
    "                            'market', 'gas station', 'store', 'restaurant', 'cafeteria', 'catering', 'bar', 'hospital',\n",
    "                            'rehabilitation', 'motel', 'dormitory', 'fraternity'\n",
    "            , 'monastery', 'showroom', 'office', 'bank', 'community', 'center', 'cinema', 'theater', 'casino',\n",
    "                            'library', 'armory', 'police station', 'fire station',\n",
    "                            'jail', 'reformatory ', 'penitentiary', 'vehicle service', 'refrigerated warehouse',\n",
    "                            'airplane hangar', 'laboratory', 'telephone switching', 'crematorium',\n",
    "                            'telephone switching', 'copy center', 'printing shop', 'tanning salon', 'probation office',\n",
    "                            'enclosed mall', 'university', 'reception hall', 'supercentre', 'museum', 'repair shop',\n",
    "                            'data center', 'enclosed mall', 'salon', 'mall', 'pool', 'swimming pool',\n",
    "                            'veterinary_care', 'jewelry_store', 'hair_care', 'gym', 'airport', 'amusement_park',\n",
    "                            'aquarium', 'aquarium', 'atm', 'bakery', 'liquor_store', 'lodging', 'night_club', 'rv_park',\n",
    "                            'supermarket', 'roofing_contractor', 'pet_store',\n",
    "                            'parking', 'park', 'moving_company', 'post_office', 'supermarket', 'taxi_stand', 'plumber',\n",
    "                            'physiotherapist', 'car_dealer', 'bowling_alley', 'book_store', 'bicycle_store',\n",
    "                            'beauty_salon', 'art_gallery',\n",
    "                            'car_dealer', 'car_wash', 'courthouse', 'hardware', 'store', 'subway', 'station', 'embassy',\n",
    "                            'drugstore', 'doctor', 'train', 'station', 'transit', 'station', 'travel', 'agency', 'pet',\n",
    "                            'store', 'night', 'club',\n",
    "                            'shoe', 'spa', 'cemetery', 'furniture', 'temple', 'hindu', 'electronics', 'dentist']}\n",
    "    resident_keywords = 0\n",
    "    non_resident_keywords = 0\n",
    "    resident_types = []\n",
    "    non_resident_types = []\n",
    "    other_types = []\n",
    "\n",
    "#Classifying Address Results into Residential, Non Residential and Other Categories\n",
    "    for word in newA:\n",
    "        if word in lib['Residential']:\n",
    "            resident_keywords += 1\n",
    "            resident_types.append(word)\n",
    "\n",
    "        elif word in lib['Non Residential']:\n",
    "            non_resident_keywords += 1\n",
    "            non_resident_types.append(word)\n",
    "        else:\n",
    "            other_types.append(word)\n",
    "\n",
    "    if resident_keywords > non_resident_keywords:\n",
    "        result = \"Residential\"\n",
    "        return result, resident_types\n",
    "    elif non_resident_keywords > resident_keywords:\n",
    "        result = \"Non Residential\"\n",
    "        return result, non_resident_types\n",
    "    else:\n",
    "        result = \"Other\"\n",
    "        return result, other_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_result(street_number, street_name, street_type, postal_code):\n",
    "    street_number = int(street_number)\n",
    "    new_df = pd.DataFrame({\"postal_code\": [postal_code], \"street_number\": [street_number], \"street_name\": [street_name],\n",
    "                           'street_type': [street_type]})\n",
    "    tfidfconverter = loaded_model._vectorizer  # keeping the same vectorizer as in model\n",
    "    # new_df['street_number'] = tfidfconverter.transform(new_df['street_number']).toarray()\n",
    "    new_df['street_name'] = tfidfconverter.transform(new_df['street_name']).toarray()\n",
    "    new_df['street_type'] = tfidfconverter.transform(new_df['street_type']).toarray()\n",
    "    new_df['postal_code'] = tfidfconverter.transform(new_df['postal_code']).toarray()\n",
    "    result = str(loaded_model.predict(new_df)[0])\n",
    "    prob = list(loaded_model.predict_proba(new_df)[0])\n",
    "    if result == \"Residential\":\n",
    "        score = prob[1]\n",
    "\n",
    "    else:\n",
    "        score = prob[0]\n",
    "\n",
    "    return result, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Hook to Integrate Code With Google Dialogueflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route(\"/webhook\", methods=['GET', 'POST'])\n",
    "def webhook():\n",
    "    response = request.json\n",
    "    input = response['queryResult']['parameters']['address']\n",
    "    address = get_formatted_address(input)\n",
    "    web_address = address\n",
    "    print(address)\n",
    "    address = address.replace(', Canada', '')\n",
    "    address_list = address.split(',')\n",
    "    street_number = address_list[0].split(' ')[0]\n",
    "    street_type = address_list[0].split(' ')[-1]\n",
    "    street_name_list = address_list[0].split(' ')\n",
    "    street_name_list.remove(street_number)\n",
    "    street_name_list.remove(street_type)\n",
    "    street_name = \" \".join(street_name_list)\n",
    "    temp = address_list[-1].split(' ')\n",
    "    postal_code = temp[-2] + temp[-1]\n",
    "    model_result, score = get_model_result(street_number, street_name, street_type, postal_code)\n",
    "    print(\"Model result: \", model_result)\n",
    "    print(\"score: \", score)\n",
    "    web_result, types = get_result(web_address)\n",
    "    print(\"web result: \", web_result)\n",
    "    map = get_map_image(web_address)\n",
    "    street_view = get_street_view(web_address)\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    if model_result != web_result:\n",
    "        if score > model_threshold:\n",
    "            final_result = \"Mixed Residential and Non Residential\"\n",
    "            result['fulfillmentText'] = final_result + \"[\" + \",\".join(types) + \"]\"\n",
    "        else:\n",
    "            final_result = web_result\n",
    "            result['fulfillmentText'] = final_result + \"[\" + \",\".join(types) + \"]\"\n",
    "    else:\n",
    "        final_result = web_result\n",
    "        result['fulfillmentText'] = final_result + \"[\" + \",\".join(types) + \"]\"\n",
    "\n",
    "    result['fulfillmentMessages'] = [\n",
    "        {\n",
    "            \"card\": {\n",
    "                \"title\": result['fulfillmentText'],\n",
    "                \"imageUri\": map\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"card\": {\n",
    "                \"title\": result['fulfillmentText'],\n",
    "                \"imageUri\": street_view\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    print(json.dumps(result))\n",
    "    return jsonify(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
